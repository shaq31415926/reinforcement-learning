{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "985cdf66-fdc1-4818-9d4f-0c13e702e6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-02 10:45:07.672627: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from stable_baselines3 import PPO # the algorithm we are importing\n",
    "# reference: https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "# vectorise environment - train on multiple agents\n",
    "# wrapper around environment\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c93a1049-acd2-40b8-b521-4c9e7f81aea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_name = \"CarRacing-v2\"\n",
    "env = gym.make(environment_name, render_mode=\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86e92399-61d3-40c0-8a68-e3dc626e837c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]], dtype=uint8),\n",
       " {})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0ebda35-3ed1-4893-84ee-263643933bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a43280cc-e5f9-48ac-83ac-ee4afea7d8cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-1.  0.  0.], 1.0, (3,), float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17926191-c566-4e59-be6c-ccca1faf34c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.07575095,  0.90505934,  0.05047554], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67ce6973-9c20-4bec-829f-670ab6a5eb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/rl/lib/python3.11/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode #: 1\n",
      "Score: -860.660431654781\n",
      "Episode #: 2\n",
      "Score: -409.7708609271526\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m     env\u001b[38;5;241m.\u001b[39mrender()\n\u001b[1;32m     12\u001b[0m     action \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39msample() \u001b[38;5;66;03m# we are taking random actions, left and right\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m     n_state, reward, done, _, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m     14\u001b[0m     score \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpisode #: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/rl/lib/python3.11/site-packages/gym/wrappers/time_limit.py:50\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[1;32m     40\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/rl/lib/python3.11/site-packages/gym/wrappers/order_enforcing.py:37\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/rl/lib/python3.11/site-packages/gym/wrappers/env_checker.py:39\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/rl/lib/python3.11/site-packages/gym/envs/box2d/car_racing.py:541\u001b[0m, in \u001b[0;36mCarRacing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworld\u001b[38;5;241m.\u001b[39mStep(\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m FPS, \u001b[38;5;241m6\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m)\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m FPS\n\u001b[0;32m--> 541\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_render(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_pixels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    543\u001b[0m step_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    544\u001b[0m terminated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/rl/lib/python3.11/site-packages/gym/envs/box2d/car_racing.py:591\u001b[0m, in \u001b[0;36mCarRacing._render\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m  \u001b[38;5;66;03m# reset() not called yet\u001b[39;00m\n\u001b[0;32m--> 591\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf \u001b[38;5;241m=\u001b[39m pygame\u001b[38;5;241m.\u001b[39mSurface((WINDOW_W, WINDOW_H))\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcar \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;66;03m# computing transformations\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = gym.make(environment_name, render_mode=\"human\")\n",
    "\n",
    "episodes = 5\n",
    "\n",
    "for e in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample() # we are taking random actions, left and right\n",
    "        n_state, reward, done, _, info = env.step(action)\n",
    "        score += reward\n",
    "    print(f\"Episode #: {e}\")\n",
    "    print(f\"Score: {score}\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d35d8b07-9e0a-45c3-919c-fd17d27c928e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/rl/lib/python3.11/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "# create our environment again\n",
    "env = gym.make(environment_name, render_mode=\"human\")\n",
    "# vectorise our environment\n",
    "env = DummyVecEnv([lambda:env])\n",
    "# import the algorithm\n",
    "model = PPO(\"CnnPolicy\", env, verbose=1, tensorboard_log=\"training/logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9ed035b-52a5-4a54-9acf-67882b05c4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to training/logs/PPO_6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/rl/lib/python3.11/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 46   |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 44   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 36          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 113         |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005497046 |\n",
      "|    clip_fraction        | 0.0736      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.26       |\n",
      "|    explained_variance   | 0.00633     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.184       |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00366    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.741       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 33          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 182         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011760253 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.26       |\n",
      "|    explained_variance   | 0.247       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.142       |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00996    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.504       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 32          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 252         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009722503 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.24       |\n",
      "|    explained_variance   | 0.155       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.141       |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00923    |\n",
      "|    std                  | 0.987       |\n",
      "|    value_loss           | 0.516       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 31          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 329         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013827779 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.2        |\n",
      "|    explained_variance   | 0.215       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.174       |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 0.974       |\n",
      "|    value_loss           | 0.489       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 437         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010488074 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.17       |\n",
      "|    explained_variance   | 0.209       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0628      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 0.97        |\n",
      "|    value_loss           | 0.374       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 23          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 616         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011552624 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.14       |\n",
      "|    explained_variance   | 0.0886      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0776      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    std                  | 0.953       |\n",
      "|    value_loss           | 0.379       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 794         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011474103 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.1        |\n",
      "|    explained_variance   | 0.0207      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.138       |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    std                  | 0.948       |\n",
      "|    value_loss           | 0.393       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 989         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017842483 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.08       |\n",
      "|    explained_variance   | 0.131       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0212      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0225     |\n",
      "|    std                  | 0.94        |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 1175        |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021014044 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.05       |\n",
      "|    explained_variance   | 0.677       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00563    |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0259     |\n",
      "|    std                  | 0.927       |\n",
      "|    value_loss           | 0.284       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 1326        |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018308938 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.01       |\n",
      "|    explained_variance   | 0.513       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.129       |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0242     |\n",
      "|    std                  | 0.92        |\n",
      "|    value_loss           | 0.269       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 1462        |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017092614 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.99       |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.158       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    std                  | 0.912       |\n",
      "|    value_loss           | 0.496       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 1594        |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018514588 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.94       |\n",
      "|    explained_variance   | 0.811       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0777      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    std                  | 0.894       |\n",
      "|    value_loss           | 0.331       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 16        |\n",
      "|    iterations           | 14        |\n",
      "|    time_elapsed         | 1708      |\n",
      "|    total_timesteps      | 28672     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0211026 |\n",
      "|    clip_fraction        | 0.222     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -3.9      |\n",
      "|    explained_variance   | 0.808     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0851    |\n",
      "|    n_updates            | 130       |\n",
      "|    policy_gradient_loss | -0.0297   |\n",
      "|    std                  | 0.884     |\n",
      "|    value_loss           | 0.318     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 1815        |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020702492 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.87       |\n",
      "|    explained_variance   | 0.823       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0675      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    std                  | 0.878       |\n",
      "|    value_loss           | 0.365       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 1922        |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022680562 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.83       |\n",
      "|    explained_variance   | 0.855       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0223      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0264     |\n",
      "|    std                  | 0.865       |\n",
      "|    value_loss           | 0.27        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 2013        |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028350363 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.8        |\n",
      "|    explained_variance   | 0.849       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.114       |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0279     |\n",
      "|    std                  | 0.856       |\n",
      "|    value_loss           | 0.482       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 2077        |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032312304 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.76       |\n",
      "|    explained_variance   | 0.919       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0056     |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    std                  | 0.843       |\n",
      "|    value_loss           | 0.358       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 18         |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 2148       |\n",
      "|    total_timesteps      | 38912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03133542 |\n",
      "|    clip_fraction        | 0.277      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.72      |\n",
      "|    explained_variance   | 0.882      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.183      |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.0301    |\n",
      "|    std                  | 0.833      |\n",
      "|    value_loss           | 0.597      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 18         |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 2222       |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03694726 |\n",
      "|    clip_fraction        | 0.301      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.69      |\n",
      "|    explained_variance   | 0.905      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.124      |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.0318    |\n",
      "|    std                  | 0.827      |\n",
      "|    value_loss           | 0.465      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 2296        |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031620312 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.66       |\n",
      "|    explained_variance   | 0.692       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.162       |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    std                  | 0.821       |\n",
      "|    value_loss           | 1.14        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 18         |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 2414       |\n",
      "|    total_timesteps      | 45056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03943161 |\n",
      "|    clip_fraction        | 0.334      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.63      |\n",
      "|    explained_variance   | 0.476      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.208      |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.0383    |\n",
      "|    std                  | 0.808      |\n",
      "|    value_loss           | 0.947      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 2686        |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027138716 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.58       |\n",
      "|    explained_variance   | 0.895       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.229       |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    std                  | 0.798       |\n",
      "|    value_loss           | 1.11        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 16         |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 2976       |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04166948 |\n",
      "|    clip_fraction        | 0.333      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.55      |\n",
      "|    explained_variance   | 0.244      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.435      |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.0193    |\n",
      "|    std                  | 0.789      |\n",
      "|    value_loss           | 2.19       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 15         |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 3287       |\n",
      "|    total_timesteps      | 51200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04036399 |\n",
      "|    clip_fraction        | 0.312      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.52      |\n",
      "|    explained_variance   | 0.873      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.109      |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.0269    |\n",
      "|    std                  | 0.784      |\n",
      "|    value_loss           | 1.59       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 3431        |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039858498 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.5        |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0672      |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    std                  | 0.778       |\n",
      "|    value_loss           | 0.511       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 3529        |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031886768 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.48       |\n",
      "|    explained_variance   | 0.669       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.27        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0237     |\n",
      "|    std                  | 0.774       |\n",
      "|    value_loss           | 3.21        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 3627        |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038081992 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.46       |\n",
      "|    explained_variance   | 0.936       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0456      |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 0.771       |\n",
      "|    value_loss           | 1.03        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 3728        |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044630095 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.45       |\n",
      "|    explained_variance   | 0.921       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.709       |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    std                  | 0.768       |\n",
      "|    value_loss           | 3.76        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 16         |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 3827       |\n",
      "|    total_timesteps      | 61440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04546968 |\n",
      "|    clip_fraction        | 0.323      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.43      |\n",
      "|    explained_variance   | 0.769      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.04       |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.0178    |\n",
      "|    std                  | 0.763      |\n",
      "|    value_loss           | 6.05       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 3926        |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047918946 |\n",
      "|    clip_fraction        | 0.362       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.42       |\n",
      "|    explained_variance   | 0.621       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.3         |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 0.759       |\n",
      "|    value_loss           | 4.6         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 4015        |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032099135 |\n",
      "|    clip_fraction        | 0.395       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.4        |\n",
      "|    explained_variance   | 0.759       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.11        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0035     |\n",
      "|    std                  | 0.756       |\n",
      "|    value_loss           | 4.01        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 16         |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 4071       |\n",
      "|    total_timesteps      | 67584      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06744195 |\n",
      "|    clip_fraction        | 0.336      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.39      |\n",
      "|    explained_variance   | 0.929      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.548      |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.00866   |\n",
      "|    std                  | 0.752      |\n",
      "|    value_loss           | 3.59       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 4128        |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046946503 |\n",
      "|    clip_fraction        | 0.377       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.37       |\n",
      "|    explained_variance   | 0.728       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.661       |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00515    |\n",
      "|    std                  | 0.748       |\n",
      "|    value_loss           | 7.27        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 4186        |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041675046 |\n",
      "|    clip_fraction        | 0.431       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.35       |\n",
      "|    explained_variance   | 0.737       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.03        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | 0.011       |\n",
      "|    std                  | 0.743       |\n",
      "|    value_loss           | 7.07        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 4244        |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046307936 |\n",
      "|    clip_fraction        | 0.362       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.34       |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.125       |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00505    |\n",
      "|    std                  | 0.741       |\n",
      "|    value_loss           | 3.63        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 17         |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 4301       |\n",
      "|    total_timesteps      | 75776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06392588 |\n",
      "|    clip_fraction        | 0.413      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.33      |\n",
      "|    explained_variance   | 0.91       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.78       |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.00565   |\n",
      "|    std                  | 0.741      |\n",
      "|    value_loss           | 7.83       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 17         |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 4360       |\n",
      "|    total_timesteps      | 77824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10440489 |\n",
      "|    clip_fraction        | 0.358      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.32      |\n",
      "|    explained_variance   | 0.94       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.35       |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | 0.00421    |\n",
      "|    std                  | 0.736      |\n",
      "|    value_loss           | 7.21       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 17         |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 4437       |\n",
      "|    total_timesteps      | 79872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06384525 |\n",
      "|    clip_fraction        | 0.433      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.29      |\n",
      "|    explained_variance   | 0.773      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.56       |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | 0.0107     |\n",
      "|    std                  | 0.73       |\n",
      "|    value_loss           | 6.72       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 18         |\n",
      "|    iterations           | 40         |\n",
      "|    time_elapsed         | 4523       |\n",
      "|    total_timesteps      | 81920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09045124 |\n",
      "|    clip_fraction        | 0.44       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.26      |\n",
      "|    explained_variance   | 0.788      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.04       |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | 0.00434    |\n",
      "|    std                  | 0.721      |\n",
      "|    value_loss           | 7.12       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 18         |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 4632       |\n",
      "|    total_timesteps      | 83968      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05375859 |\n",
      "|    clip_fraction        | 0.419      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.24      |\n",
      "|    explained_variance   | 0.946      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.6        |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | 0.0102     |\n",
      "|    std                  | 0.72       |\n",
      "|    value_loss           | 6.63       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 18         |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 4770       |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05331704 |\n",
      "|    clip_fraction        | 0.413      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.23      |\n",
      "|    explained_variance   | 0.965      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.481      |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.00432   |\n",
      "|    std                  | 0.721      |\n",
      "|    value_loss           | 4.4        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 17         |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 4900       |\n",
      "|    total_timesteps      | 88064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09992402 |\n",
      "|    clip_fraction        | 0.498      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.24      |\n",
      "|    explained_variance   | 0.88       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.87       |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | 0.0252     |\n",
      "|    std                  | 0.721      |\n",
      "|    value_loss           | 21.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 17         |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 5029       |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09521685 |\n",
      "|    clip_fraction        | 0.495      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.24      |\n",
      "|    explained_variance   | 0.916      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.779      |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | 0.00842    |\n",
      "|    std                  | 0.721      |\n",
      "|    value_loss           | 9.02       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 17         |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 5160       |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09672925 |\n",
      "|    clip_fraction        | 0.513      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.24      |\n",
      "|    explained_variance   | 0.835      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.6        |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | 0.0359     |\n",
      "|    std                  | 0.723      |\n",
      "|    value_loss           | 25.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 17         |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 5289       |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07622026 |\n",
      "|    clip_fraction        | 0.551      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.24      |\n",
      "|    explained_variance   | 0.638      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.85       |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | 0.0361     |\n",
      "|    std                  | 0.721      |\n",
      "|    value_loss           | 17.9       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 17         |\n",
      "|    iterations           | 47         |\n",
      "|    time_elapsed         | 5422       |\n",
      "|    total_timesteps      | 96256      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08328317 |\n",
      "|    clip_fraction        | 0.555      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.23      |\n",
      "|    explained_variance   | 0.757      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.8        |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | 0.0326     |\n",
      "|    std                  | 0.72       |\n",
      "|    value_loss           | 14.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 17         |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 5642       |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15482458 |\n",
      "|    clip_fraction        | 0.478      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.22      |\n",
      "|    explained_variance   | 0.852      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.16       |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | 0.00945    |\n",
      "|    std                  | 0.718      |\n",
      "|    value_loss           | 11.1       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mlearn(total_timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500000\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/rl/lib/python3.11/site-packages/stable_baselines3/ppo/ppo.py:315\u001b[0m, in \u001b[0;36mPPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[1;32m    308\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    313\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    314\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[0;32m--> 315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mlearn(\n\u001b[1;32m    316\u001b[0m         total_timesteps\u001b[38;5;241m=\u001b[39mtotal_timesteps,\n\u001b[1;32m    317\u001b[0m         callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    318\u001b[0m         log_interval\u001b[38;5;241m=\u001b[39mlog_interval,\n\u001b[1;32m    319\u001b[0m         tb_log_name\u001b[38;5;241m=\u001b[39mtb_log_name,\n\u001b[1;32m    320\u001b[0m         reset_num_timesteps\u001b[38;5;241m=\u001b[39mreset_num_timesteps,\n\u001b[1;32m    321\u001b[0m         progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[1;32m    322\u001b[0m     )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/rl/lib/python3.11/site-packages/stable_baselines3/common/on_policy_algorithm.py:313\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mep_info_buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    311\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dump_logs(iteration)\n\u001b[0;32m--> 313\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    315\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_end()\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/rl/lib/python3.11/site-packages/stable_baselines3/ppo/ppo.py:217\u001b[0m, in \u001b[0;36mPPO.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_sde:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mreset_noise(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[0;32m--> 217\u001b[0m values, log_prob, entropy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mevaluate_actions(rollout_data\u001b[38;5;241m.\u001b[39mobservations, actions)\n\u001b[1;32m    218\u001b[0m values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# Normalize advantage\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/rl/lib/python3.11/site-packages/stable_baselines3/common/policies.py:719\u001b[0m, in \u001b[0;36mActorCriticPolicy.evaluate_actions\u001b[0;34m(self, obs, actions)\u001b[0m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;124;03m    Get the action according to the policy for a given observation.\u001b[39;00m\n\u001b[1;32m    712\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;124;03m    :return: Taken action according to the policy\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_distribution(observation)\u001b[38;5;241m.\u001b[39mget_actions(deterministic\u001b[38;5;241m=\u001b[39mdeterministic)\n\u001b[0;32m--> 719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, obs: PyTorchObs, actions: th\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[th\u001b[38;5;241m.\u001b[39mTensor, th\u001b[38;5;241m.\u001b[39mTensor, Optional[th\u001b[38;5;241m.\u001b[39mTensor]]:\n\u001b[1;32m    720\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;124;03m    Evaluate actions according to the current policy,\u001b[39;00m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;124;03m    given the observations.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;124;03m        and entropy of the action distribution.\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    729\u001b[0m     \u001b[38;5;66;03m# Preprocess the observation if needed\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39a2e5b-83cf-4ede-82a7-61d29199434e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save my model\n",
    "\n",
    "model.save(\"training/models/PPO_500k_Driving_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa1a7c2-6930-46a7-a664-fd496cb44e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ec9a24-006e-480e-9081-aac375eeedc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "\n",
    "model = PPO.load(\"training/models/PPO_500k_Driving_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eff5a90-9dcd-4a4f-bda8-912d18150cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "evaluate_policy(model, env, n_eval_episodes=5, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c2e2d4-c713-461a-b1d1-98391c5f10b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1759ba9f-fe91-4d25-b59b-06f8b428869a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
