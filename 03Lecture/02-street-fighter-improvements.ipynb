{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "020a8cd9-104e-401a-8a3f-7ab4927c2604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import retro\n",
    "from gym import Env # to wrap the environment\n",
    "from gym.spaces import MultiBinary, Box # \n",
    "import numpy as np # to calculate the delta between the frames\n",
    "import cv2 # for grayscaling\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a41bbbf9-1644-4b86-a43d-0ec6769b88f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating custom environment that will carry out all the steps\n",
    "# we pass our pass environment\n",
    "\n",
    "class StreetFighter(Env): \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Specify action space and observation space \n",
    "        # resizing and making gray scale\n",
    "        self.observation_space = Box(low=0, high=255, shape=(84, 84, 1), dtype=np.uint8) \n",
    "        self.action_space = MultiBinary(12)\n",
    "        # Startup and instance of the game \n",
    "        # additional parameter to filter only valid actions\n",
    "        self.game = retro.make(game='StreetFighterIISpecialChampionEdition-Genesis', use_restricted_actions=retro.Actions.FILTERED)\n",
    "    \n",
    "    def reset(self):\n",
    "        # Return the first frame \n",
    "        obs = self.game.reset()\n",
    "        obs = self.preprocess(obs) \n",
    "        self.previous_frame = obs # want to also keep track of the previous frame to calculate a delta between the frames\n",
    "        \n",
    "        # Create a attribute to hold the score delta \n",
    "        self.score = 0 \n",
    "        return obs\n",
    "    \n",
    "    def preprocess(self, observation): \n",
    "        # Grayscaling \n",
    "        gray = cv2.cvtColor(observation, cv2.COLOR_BGR2GRAY)\n",
    "        # Resize \n",
    "        resize = cv2.resize(gray, (84,84), interpolation=cv2.INTER_CUBIC)\n",
    "        # Add the channels value\n",
    "        channels = np.reshape(resize, (84,84,1))\n",
    "        return channels \n",
    "    \n",
    "    def step(self, action): \n",
    "        # Take a step \n",
    "        obs, reward, done, info = self.game.step(action)\n",
    "        obs = self.preprocess(obs) \n",
    "        \n",
    "        # Frame delta - use this to train our agent\n",
    "        frame_delta = obs - self.previous_frame\n",
    "        self.previous_frame = obs \n",
    "        \n",
    "        # Reshape the reward function\n",
    "        reward = info['score'] - self.score \n",
    "        self.score = info['score'] \n",
    "        \n",
    "        return frame_delta, reward, done, info\n",
    "    \n",
    "    def render(self, *args, **kwargs):\n",
    "        self.game.render()\n",
    "        \n",
    "    def close(self):\n",
    "        self.game.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac8fddaa-4f27-4276-b392-d8e0ed392d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "# Bring in the eval policy method for metric calculation\n",
    "\n",
    "timesteps = 1000\n",
    "model = PPO.load(f\"training/models/PPO_{timesteps}_SF\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0f9c09b-1930-4d71-95ce-bb72b10baccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/street-fighter/lib/python3.8/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n",
      "2024-06-07 21:34:46.035 python[11112:36644674] Warning: Expected min height of view: (<NSPopoverTouchBarItemButton: 0x7ff47c5ff5d0>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.\n",
      "2024-06-07 21:34:46.035 python[11112:36644674] Warning: Expected min height of view: (<NSButton: 0x7ff47c864a90>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.\n",
      "2024-06-07 21:34:46.038 python[11112:36644674] Warning: Expected min height of view: (<NSPopoverTouchBarItemButton: 0x7ff47c8527d0>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.\n",
      "2024-06-07 21:34:46.039 python[11112:36644674] Warning: Expected min height of view: (<NSPopoverTouchBarItemButton: 0x7ff47c870200>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.\n"
     ]
    }
   ],
   "source": [
    "# create environment\n",
    "env = StreetFighter()\n",
    "mean_reward, _ = evaluate_policy(model, env, render=True, n_eval_episodes=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8f5c2d6-74a9-4f65-a03e-a6a7190b3ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000.0, 0.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_reward, _ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e25a9783-c93c-4c67-bbaf-55a05b8a657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b463a0d2-e709-48c8-bde6-39ad126d9e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.12.1 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# check logs\n",
    "log_path = 'training/logs/PPO_10'\n",
    "!tensorboard --logdir={log_path}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452edc59-ad9a-4fb7-b988-b4b96c1c3d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning\n",
    "\n",
    "# install libraries for hyperparameter tuning\n",
    "!pip3 install torch torchvision optuna\n",
    "\n",
    "# resource: https://optuna.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8527dd01-556e-4af0-ba90-6e5b3c8c7156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the optimzation frame - HPO\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e553aff-09aa-44c1-b001-92ae52d39dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning - very important when it comes to RL\n",
    "# Function to return test hyperparameters - define the object function\n",
    "\n",
    "def optimize_ppo(trial): \n",
    "    return {\n",
    "        'n_steps':trial.suggest_int('n_steps', 500, 1000),\n",
    "        #'gamma':trial.suggest_loguniform('gamma', 0.8, 0.9999),\n",
    "        'learning_rate':trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
    "        #'clip_range':trial.suggest_uniform('clip_range', 0.1, 0.4),\n",
    "        #'gae_lambda':trial.suggest_uniform('gae_lambda', 0.8, 0.99)\n",
    "    }\n",
    "\n",
    "# https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html\n",
    "# video: https://www.youtube.com/watch?v=6sNIDqgICLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba9c2356-ce40-4cb2-9c14-bbb3f8597c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a training loop and return mean reward \n",
    "def optimize_agent(trial):\n",
    "    # create the experiment\n",
    "    timesteps = 1000 # increase this + n_eval_episodes for smoother performance and number trials\n",
    "    # do not hyperparameter tune on large timesteos though\n",
    "    save_path = f\"training/models/opt/PPO_{timesteps}_SF_{trial.number}\"\n",
    "\n",
    "    model_params = optimize_ppo(trial) \n",
    "\n",
    "    # Create environment \n",
    "    env = StreetFighter()\n",
    "\n",
    "    # Create algo \n",
    "    model = PPO('CnnPolicy', env, tensorboard_log=\"training/Logs\", verbose=1, **model_params)\n",
    "    model.learn(total_timesteps=timesteps)\n",
    "\n",
    "    # Evaluate model \n",
    "    mean_reward, _ = evaluate_policy(model, env, n_eval_episodes=5)\n",
    "    env.close()\n",
    "\n",
    "    model.save(save_path)\n",
    "\n",
    "    return mean_reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4fc977c0-3bb3-4c3a-bce7-1b791698f01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-07 21:48:31,330] A new study created in memory with name: no-name-87c3b552-db05-4dbb-a1b2-7cc45406076d\n",
      "/var/folders/gs/c69h38_15hb4fnkpnc9gvksm0000gn/T/ipykernel_11112/3701864106.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "/opt/miniconda3/envs/street-fighter/lib/python3.8/site-packages/stable_baselines3/ppo/ppo.py:145: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 814`, after every 12 untruncated mini-batches, there will be a truncated mini-batch of size 46\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=814 and n_envs=1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to training/Logs/PPO_13\n",
      "----------------------------\n",
      "| time/              |     |\n",
      "|    fps             | 385 |\n",
      "|    iterations      | 1   |\n",
      "|    time_elapsed    | 2   |\n",
      "|    total_timesteps | 814 |\n",
      "----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 1628        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008379249 |\n",
      "|    clip_fraction        | 0.0532      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.31       |\n",
      "|    explained_variance   | -0.000622   |\n",
      "|    learning_rate        | 2.3e-05     |\n",
      "|    loss                 | 2.38e+03    |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00681    |\n",
      "|    value_loss           | 5.21e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-07 21:49:48,996] Trial 0 finished with value: 1000.0 and parameters: {'n_steps': 814, 'learning_rate': 2.295270625385499e-05}. Best is trial 0 with value: 1000.0.\n",
      "/opt/miniconda3/envs/street-fighter/lib/python3.8/site-packages/stable_baselines3/ppo/ppo.py:145: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 915`, after every 14 untruncated mini-batches, there will be a truncated mini-batch of size 19\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=915 and n_envs=1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to training/Logs/PPO_14\n",
      "----------------------------\n",
      "| time/              |     |\n",
      "|    fps             | 314 |\n",
      "|    iterations      | 1   |\n",
      "|    time_elapsed    | 2   |\n",
      "|    total_timesteps | 915 |\n",
      "----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 100          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 18           |\n",
      "|    total_timesteps      | 1830         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059193387 |\n",
      "|    clip_fraction        | 0.0255       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.32        |\n",
      "|    explained_variance   | -0.000259    |\n",
      "|    learning_rate        | 1.43e-05     |\n",
      "|    loss                 | 23.3         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00625     |\n",
      "|    value_loss           | 3.19e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-07 21:52:08,262] Trial 1 finished with value: 2000.0 and parameters: {'n_steps': 915, 'learning_rate': 1.4257329420365463e-05}. Best is trial 1 with value: 2000.0.\n",
      "/opt/miniconda3/envs/street-fighter/lib/python3.8/site-packages/stable_baselines3/ppo/ppo.py:145: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 599`, after every 9 untruncated mini-batches, there will be a truncated mini-batch of size 23\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=599 and n_envs=1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to training/Logs/PPO_15\n",
      "----------------------------\n",
      "| time/              |     |\n",
      "|    fps             | 293 |\n",
      "|    iterations      | 1   |\n",
      "|    time_elapsed    | 2   |\n",
      "|    total_timesteps | 599 |\n",
      "----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 1198        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006880082 |\n",
      "|    clip_fraction        | 0.0501      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.32       |\n",
      "|    explained_variance   | -13.4       |\n",
      "|    learning_rate        | 9.53e-05    |\n",
      "|    loss                 | -0.0795     |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0344     |\n",
      "|    value_loss           | 0.00666     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-07 21:53:40,641] Trial 2 finished with value: 3300.0 and parameters: {'n_steps': 599, 'learning_rate': 9.533441326698291e-05}. Best is trial 2 with value: 3300.0.\n",
      "/opt/miniconda3/envs/street-fighter/lib/python3.8/site-packages/stable_baselines3/ppo/ppo.py:145: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 974`, after every 15 untruncated mini-batches, there will be a truncated mini-batch of size 14\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=974 and n_envs=1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to training/Logs/PPO_16\n",
      "----------------------------\n",
      "| time/              |     |\n",
      "|    fps             | 308 |\n",
      "|    iterations      | 1   |\n",
      "|    time_elapsed    | 3   |\n",
      "|    total_timesteps | 974 |\n",
      "----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 1948         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0099665485 |\n",
      "|    clip_fraction        | 0.0529       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.31        |\n",
      "|    explained_variance   | 0.000351     |\n",
      "|    learning_rate        | 2.94e-05     |\n",
      "|    loss                 | 2.83e+03     |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00473     |\n",
      "|    value_loss           | 4.3e+03      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-07 21:57:55,056] Trial 3 finished with value: 56700.0 and parameters: {'n_steps': 974, 'learning_rate': 2.9448191982907483e-05}. Best is trial 3 with value: 56700.0.\n",
      "/opt/miniconda3/envs/street-fighter/lib/python3.8/site-packages/stable_baselines3/ppo/ppo.py:145: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 630`, after every 9 untruncated mini-batches, there will be a truncated mini-batch of size 54\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=630 and n_envs=1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to training/Logs/PPO_17\n",
      "----------------------------\n",
      "| time/              |     |\n",
      "|    fps             | 332 |\n",
      "|    iterations      | 1   |\n",
      "|    time_elapsed    | 1   |\n",
      "|    total_timesteps | 630 |\n",
      "----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 1260        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012875857 |\n",
      "|    clip_fraction        | 0.0579      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.31       |\n",
      "|    explained_variance   | 0.000959    |\n",
      "|    learning_rate        | 4.04e-05    |\n",
      "|    loss                 | 1.8e+03     |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00571    |\n",
      "|    value_loss           | 3.38e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-07 22:00:13,746] Trial 4 finished with value: 2000.0 and parameters: {'n_steps': 630, 'learning_rate': 4.040120879188815e-05}. Best is trial 3 with value: 56700.0.\n",
      "/opt/miniconda3/envs/street-fighter/lib/python3.8/site-packages/stable_baselines3/ppo/ppo.py:145: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 770`, after every 12 untruncated mini-batches, there will be a truncated mini-batch of size 2\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=770 and n_envs=1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to training/Logs/PPO_18\n",
      "----------------------------\n",
      "| time/              |     |\n",
      "|    fps             | 375 |\n",
      "|    iterations      | 1   |\n",
      "|    time_elapsed    | 2   |\n",
      "|    total_timesteps | 770 |\n",
      "----------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 115       |\n",
      "|    iterations           | 2         |\n",
      "|    time_elapsed         | 13        |\n",
      "|    total_timesteps      | 1540      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5318988 |\n",
      "|    clip_fraction        | 0.373     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -8.18     |\n",
      "|    explained_variance   | 0.000611  |\n",
      "|    learning_rate        | 0.000114  |\n",
      "|    loss                 | 1.67e+04  |\n",
      "|    n_updates            | 10        |\n",
      "|    policy_gradient_loss | -0.00509  |\n",
      "|    value_loss           | 3.52e+03  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-07 22:01:39,046] Trial 5 finished with value: 4900.0 and parameters: {'n_steps': 770, 'learning_rate': 0.00011372450859659157}. Best is trial 3 with value: 56700.0.\n",
      "/opt/miniconda3/envs/street-fighter/lib/python3.8/site-packages/stable_baselines3/ppo/ppo.py:145: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 833`, after every 13 untruncated mini-batches, there will be a truncated mini-batch of size 1\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=833 and n_envs=1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to training/Logs/PPO_19\n",
      "----------------------------\n",
      "| time/              |     |\n",
      "|    fps             | 394 |\n",
      "|    iterations      | 1   |\n",
      "|    time_elapsed    | 2   |\n",
      "|    total_timesteps | 833 |\n",
      "----------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 14         |\n",
      "|    total_timesteps      | 1666       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18491146 |\n",
      "|    clip_fraction        | 0.376      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -8.18      |\n",
      "|    explained_variance   | -0.000593  |\n",
      "|    learning_rate        | 0.000202   |\n",
      "|    loss                 | 42.9       |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.12      |\n",
      "|    value_loss           | 3.93e+03   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-07 22:03:08,481] Trial 6 finished with value: 1000.0 and parameters: {'n_steps': 833, 'learning_rate': 0.00020184850051436205}. Best is trial 3 with value: 56700.0.\n",
      "/opt/miniconda3/envs/street-fighter/lib/python3.8/site-packages/stable_baselines3/ppo/ppo.py:145: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 706`, after every 11 untruncated mini-batches, there will be a truncated mini-batch of size 2\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=706 and n_envs=1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to training/Logs/PPO_20\n",
      "----------------------------\n",
      "| time/              |     |\n",
      "|    fps             | 319 |\n",
      "|    iterations      | 1   |\n",
      "|    time_elapsed    | 2   |\n",
      "|    total_timesteps | 706 |\n",
      "----------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 102       |\n",
      "|    iterations           | 2         |\n",
      "|    time_elapsed         | 13        |\n",
      "|    total_timesteps      | 1412      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 26.691061 |\n",
      "|    clip_fraction        | 0.826     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -5.22     |\n",
      "|    explained_variance   | -0.0018   |\n",
      "|    learning_rate        | 0.000984  |\n",
      "|    loss                 | 103       |\n",
      "|    n_updates            | 10        |\n",
      "|    policy_gradient_loss | 0.238     |\n",
      "|    value_loss           | 1.92e+04  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-07 22:05:02,148] Trial 7 finished with value: 9200.0 and parameters: {'n_steps': 706, 'learning_rate': 0.000984269778949596}. Best is trial 3 with value: 56700.0.\n",
      "/opt/miniconda3/envs/street-fighter/lib/python3.8/site-packages/stable_baselines3/ppo/ppo.py:145: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 613`, after every 9 untruncated mini-batches, there will be a truncated mini-batch of size 37\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=613 and n_envs=1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to training/Logs/PPO_21\n",
      "----------------------------\n",
      "| time/              |     |\n",
      "|    fps             | 395 |\n",
      "|    iterations      | 1   |\n",
      "|    time_elapsed    | 1   |\n",
      "|    total_timesteps | 613 |\n",
      "----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 1226         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019855374 |\n",
      "|    clip_fraction        | 0.00487      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.32        |\n",
      "|    explained_variance   | -5.92        |\n",
      "|    learning_rate        | 1.45e-05     |\n",
      "|    loss                 | -0.0441      |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00968     |\n",
      "|    value_loss           | 0.0113       |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-07 22:07:00,412] Trial 8 finished with value: 2700.0 and parameters: {'n_steps': 613, 'learning_rate': 1.4492614573932641e-05}. Best is trial 3 with value: 56700.0.\n",
      "/opt/miniconda3/envs/street-fighter/lib/python3.8/site-packages/stable_baselines3/ppo/ppo.py:145: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 517`, after every 8 untruncated mini-batches, there will be a truncated mini-batch of size 5\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=517 and n_envs=1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to training/Logs/PPO_22\n",
      "----------------------------\n",
      "| time/              |     |\n",
      "|    fps             | 352 |\n",
      "|    iterations      | 1   |\n",
      "|    time_elapsed    | 1   |\n",
      "|    total_timesteps | 517 |\n",
      "----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 1034         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050890213 |\n",
      "|    clip_fraction        | 0.0119       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.32        |\n",
      "|    explained_variance   | 0.000427     |\n",
      "|    learning_rate        | 2e-05        |\n",
      "|    loss                 | 34.9         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00702     |\n",
      "|    value_loss           | 1.5e+04      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-07 22:08:49,135] Trial 9 finished with value: 2000.0 and parameters: {'n_steps': 517, 'learning_rate': 2.0040580824160887e-05}. Best is trial 3 with value: 56700.0.\n"
     ]
    }
   ],
   "source": [
    "# Creating the experiment \n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(optimize_agent, n_trials=10, n_jobs=1) # training for n x number of steps\n",
    "#study.optimize(optimize_agent, n_trials=100, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d24a669-cba8-45e9-b268-16ffe24a599d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_steps': 974, 'learning_rate': 2.9448191982907483e-05}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params\n",
    "\n",
    "# pass these values in your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b4e21b95-928d-4011-943e-c84bf422c551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model\n",
    "\n",
    "model = PPO.load(\"training/models/opt/PPO_1000_SF_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f798348b-56c4-4256-bf03-4d97e1d1f17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-07 22:21:11.477 python[11112:36644674] Warning: Expected min height of view: (<NSPopoverTouchBarItemButton: 0x7ff46f5a73b0>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.\n",
      "2024-06-07 22:21:11.478 python[11112:36644674] Warning: Expected min height of view: (<NSButton: 0x7ff44fe21160>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.\n",
      "2024-06-07 22:21:11.480 python[11112:36644674] Warning: Expected min height of view: (<NSPopoverTouchBarItemButton: 0x7ff44fe23240>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.\n",
      "2024-06-07 22:21:11.483 python[11112:36644674] Warning: Expected min height of view: (<NSPopoverTouchBarItemButton: 0x7ff44fe294e0>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.\n"
     ]
    }
   ],
   "source": [
    "# Create environment \n",
    "env = StreetFighter()\n",
    "\n",
    "mean_reward, _ = evaluate_policy(model, env, render=True, n_eval_episodes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "75dbdeb6-81f5-42a1-9f52-af54e1203426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56700.0, 0.0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_reward, _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "90bd7bd2-db75-48fd-b1d6-e461a64264d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d77318-aec3-48aa-b32e-a3fce2efe79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fine tuning on further steps, watch the tutorial here:\n",
    "# https://www.youtube.com/watch?v=rzbFhu6So5U (1 hour 59 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f854dfe7-3dca-4f6b-b4f1-ab1e4d4fcfc2",
   "metadata": {},
   "source": [
    "**Exam Project: You have 24 hours - Can you improve the score of the AI agent?**\n",
    "\n",
    "Some suggestions, aside from increasing the training steps (which is not enough to get an excellent grade)..\n",
    "- Could you try a different algorithm for e.g. Deep Q-Network? \n",
    "- Hyperparameter Tuning\n",
    "- Experiment with a different reward function?\n",
    "\n",
    "You are expected to increase the score of the current AI agent and showcase the experiments you carried out to increase the score. The best score will be the overall winner but you will be graded on how you applied the concepts from the course and your own research to increase the score.\n",
    "\n",
    "Resource: https://www.youtube.com/watch?v=rzbFhu6So5U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7622dd-e50b-4061-8e4f-b19eb8994fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
